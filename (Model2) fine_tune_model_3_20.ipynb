{"cells":[{"cell_type":"markdown","metadata":{"id":"gClY4ErevZyD"},"source":["#Step 0: Installation of Packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrzboXHOvYP3","outputId":"79880890-9040-4d81-af4e-a77ed4291a6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: wandb 0.19.8\n","Uninstalling wandb-0.19.8:\n","  Successfully uninstalled wandb-0.19.8\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/664.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m"]}],"source":["!pip uninstall -y wandb     # avoid experiment tracking\n","!pip install transformers[torch] -q\n","!pip install dataset -q\n","!pip install evaluate -q\n","!pip install evaluate -q\n"]},{"cell_type":"markdown","metadata":{"id":"Yh7bNBXavhJh"},"source":["#Step 1: Obtain your own dataset-bgspaditya/byt-malicious-url-treatment | 載入惡意網址分類資料"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9awxrmOpvhhw"},"outputs":[],"source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"bgspaditya/byt-malicious-url-treatment\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DuW6VtZwEbh"},"outputs":[],"source":["from datasets import Dataset, DatasetDict, load_dataset\n","\n","# Load train and test splits separately | # 載入訓練與測試資料\n","train_dataset = load_dataset(\"bgspaditya/byt-malicious-url-treatment\", split=\"train[100000:]\")\n","test_dataset = load_dataset(\"bgspaditya/byt-malicious-url-treatment\", split=\"test[:100000]\")\n","# Create a DatasetDict\n","dataset = DatasetDict({\n","    \"train\": train_dataset,\n","    \"test\": test_dataset,\n","})\n","\n","print(f\"data type = type(dataset)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHAmPc-NwJ7_"},"outputs":[],"source":["# Dataset structure\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"xfwBrYipvxuh"},"source":["#Step 2: Create the model and tokenizer objects | 建立模型與 tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NgiCpxrpwMXP"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","\n","# Load a pre-trained transformer model for classification task (DistilBERT)\n","# 載入 DistilBERT 預訓練模型並設為分類任務模型（此處指定4個類別）\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\",num_labels=4) # Define number of output classes | 輸出分類數量=4\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"]},{"cell_type":"markdown","metadata":{"id":"d18Pqkolvsd9"},"source":["#Step 3: Generate Dataset for Funetuning | 建立微調\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Tpw-PjOxI09"},"outputs":[],"source":["type(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rM3GEHSxLE4"},"outputs":[],"source":["from transformers import AutoTokenizer\n","# 'Please categlorize the url into the following type: Benign, defacement, malware, phishing',\n","# Tokenization function for processing URL input and attaching labels\n","# 定義 tokenization 函數：處理 URL 欄位並加上對應的標籤（type_code）\n","def tokenize_function(examples):\n","    appended_example = [f'Please categorize the url into the following type: Benign, defacement, malware, phishing. URL:{e}' for e in examples[\"url\"]]\n","    tokenized_inputs = tokenizer(appended_example, padding=\"max_length\", truncation=True, max_length=256)\n","    tokenized_inputs[\"labels\"] = examples[\"type_code\"] # Add label column required by model\n","\n","    return tokenized_inputs\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZL83ucY3s0MI"},"outputs":[],"source":["small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(15000)) # Selected top 15,000 pens for training set | 訓練集選取前15000筆\n","small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10000))  # Selected top 10,000 pens for testing set | 驗證集選取前10000筆\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHFEvEy1xONP"},"outputs":[],"source":["print(small_train_dataset[5])"]},{"cell_type":"markdown","metadata":{"id":"w_4MfyCBxS0X"},"source":["#Step 4a: Finetune the pre-trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kEECN7GYxTb7"},"outputs":[],"source":["from transformers import TrainingArguments\n","from evaluate import load\n","from transformers import TrainingArguments, Trainer\n","import numpy as np\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# Load accuracy | 載入準確率\n","metric = load(\"accuracy\")\n","\n","# Define metric computation function | 定義計算評估指標的函數\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","# Set training arguments | 設定模型訓練參數\n","training_args = TrainingArguments(\n","    output_dir=\"test_trainer\",\n","    num_train_epochs=4,\n","    eval_strategy=\"epoch\",\n","    weight_decay = 0.1\n","\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=small_train_dataset,\n","    eval_dataset=small_eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Start model training | 開始訓練模型\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"OPBquN0QxgLu"},"source":["#Step 4b: Evaluate the finetuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwH8ebVAxgiW"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"v_TQPgcexmxk"},"source":["#Step 4c: Save the finetuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIjmeRgzxnZL"},"outputs":[],"source":["trainer.save_model('./fine_tuned_model')\n","tokenizer.save_pretrained(\"./fine_tuned_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15168,"status":"ok","timestamp":1742748600544,"user":{"displayName":"Bucky Fok","userId":"00919578434261808440"},"user_tz":-480},"id":"mam8oS8Mxqcg","outputId":"ff722ba6-dd1f-456e-d090-3f3704e1528b"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: fine_tuned_model/ (stored 0%)\n","  adding: fine_tuned_model/config.json (deflated 50%)\n","  adding: fine_tuned_model/special_tokens_map.json (deflated 42%)\n","  adding: fine_tuned_model/tokenizer.json (deflated 71%)\n","  adding: fine_tuned_model/vocab.txt (deflated 53%)\n","  adding: fine_tuned_model/training_args.bin (deflated 51%)\n","  adding: fine_tuned_model/tokenizer_config.json (deflated 75%)\n","  adding: fine_tuned_model/model.safetensors (deflated 8%)\n"]}],"source":["!zip -r fine_tuned_model.zip fine_tuned_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3630,"status":"ok","timestamp":1742748604180,"user":{"displayName":"Bucky Fok","userId":"00919578434261808440"},"user_tz":-480},"id":"th2oKXDe4SJV","outputId":"bc2d1dd4-ac40-4772-e8ef-278ada950eba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/fine_tuned_model.zip\n","   creating: /content/fine_tuned_model/fine_tuned_model/\n","  inflating: /content/fine_tuned_model/fine_tuned_model/config.json  \n","  inflating: /content/fine_tuned_model/fine_tuned_model/special_tokens_map.json  \n","  inflating: /content/fine_tuned_model/fine_tuned_model/tokenizer.json  \n","  inflating: /content/fine_tuned_model/fine_tuned_model/vocab.txt  \n","  inflating: /content/fine_tuned_model/fine_tuned_model/training_args.bin  \n","  inflating: /content/fine_tuned_model/fine_tuned_model/tokenizer_config.json  \n","  inflating: /content/fine_tuned_model/fine_tuned_model/model.safetensors  \n"]}],"source":["!unzip \"/content/fine_tuned_model.zip\" -d \"/content/fine_tuned_model/\""]},{"cell_type":"markdown","metadata":{"id":"ykfM3GSwxtwF"},"source":["#Step 5: Test the saved model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xo4-JGN_xuII"},"outputs":[],"source":["from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n","\n","# Load Fine-tuned Model | 載入先前訓練好的模型\n","model_path = \"./fine_tuned_model/fine_tuned_model\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","\n","# Create Classification Pipeline | 建立分類任務的 pipeline\n","classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n","\n","# Define Test Samples\n","test_domains = [\n","    \"pornhub.com/video?c=b\",                        # Safe Website | 安全網站（Benign）\n","    \"http://bon-dom.com/poleznyie-stati/index.html\",            # Suspicious website | 可疑網站（可能是惡意）\n","    \"apple-verfiy.com\",                          # Look like Apple, but actually suspicious | 看似 Apple，但其實可疑\n","    \"meetyourneighbour.ca\"                         # Suspicious url 可疑域名\n","]\n","\n","# Define label map | 對模型輸出的 label 編號做轉換（對應類別名稱）\n","label_map = {\n","    0: \"Benign\",      # 安全網站\n","    1: \"defacement\",    # 網頁被篡改\n","    2: \"malware\",      # 惡意軟件\n","    3: \"phishing\"      # 網絡釣魚\n","}\n","\n","# Run Inference and Pretty Print Results\n","print(\"=== Inference Results ===\\n\")\n","for domain in test_domains:\n","    result = classifier(domain)[0]\n","    print(result)\n","    # Parses label, removes “LABEL_” and converts to an integer. | 解析 label，去掉 \"LABEL_\" 並轉換成整數\n","    label_int = int(result['label'].replace(\"LABEL_\", \"\"))\n","\n","    # Get the corresponding text tag | 獲取對應的的文本標簽\n","    label = label_map.get(label_int, \"Unknown\")\n","\n","    # Obtain the confidence level of the model | 獲取模型的置信度\n","    score = result['score']\n","\n","    print(f\"Domain: {domain:<35} → Prediction: {label:<20} | Score: {score:.4f}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z4x_g1pixSYd"},"source":["\n","\n","#Upload | 上傳"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"reOGoBW6xXhq","outputId":"e0d05f1f-2807-4835-dfe2-a66ff910692d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): "]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7q5SVvbxZYt"},"outputs":[],"source":["repo_name = \"Eason918/malicious-url-detector\"\n","\n","model.push_to_hub(repo_name)\n","tokenizer.push_to_hub(repo_name)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}